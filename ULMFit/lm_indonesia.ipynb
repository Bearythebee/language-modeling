{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH = pathlib.Path(\"lm-data/wiki_extr/id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_PATH=Path('lm-data/id/lm/')\n",
    "LM_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lm-data/wiki_extr/id/AA/wiki_00',\n",
       " 'lm-data/wiki_extr/id/AA/wiki_01',\n",
       " 'lm-data/wiki_extr/id/AA/wiki_02',\n",
       " 'lm-data/wiki_extr/id/AA/wiki_03',\n",
       " 'lm-data/wiki_extr/id/AA/wiki_04']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_FILENAMES = [str(f) for f in PATH.rglob(\"*/wiki_*\")]\n",
    "print(len(LANG_FILENAMES))\n",
    "LANG_FILENAMES[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [00:04<00:00, 122.78it/s]\n"
     ]
    }
   ],
   "source": [
    "LANG_TEXT = []\n",
    "for fn in tqdm(LANG_FILENAMES):\n",
    "    for line in open(fn, encoding='utf8'):\n",
    "        LANG_TEXT.append(json.loads(line))\n",
    "        \n",
    "LANG_TEXT = pd.DataFrame(LANG_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Asam deoksiribonukleat\\n\\nAsam deoksiribonukle...</td>\n",
       "      <td>Asam deoksiribonukleat</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Anwar Sadat\\n\\nJenderal Besar Mohammed Anwar A...</td>\n",
       "      <td>Anwar Sadat</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Azhar Mansor\\n\\nDatuk Azhar Mansor adalah oran...</td>\n",
       "      <td>Azhar Mansor</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Arkeologi\\n\\nArkeologi atau ilmu kepurbakalaan...</td>\n",
       "      <td>Arkeologi</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Antropologi\\n\\nAntropologi adalah ilmu tentang...</td>\n",
       "      <td>Antropologi</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text  \\\n",
       "0  1  Asam deoksiribonukleat\\n\\nAsam deoksiribonukle...   \n",
       "1  3  Anwar Sadat\\n\\nJenderal Besar Mohammed Anwar A...   \n",
       "2  4  Azhar Mansor\\n\\nDatuk Azhar Mansor adalah oran...   \n",
       "3  5  Arkeologi\\n\\nArkeologi atau ilmu kepurbakalaan...   \n",
       "4  6  Antropologi\\n\\nAntropologi adalah ilmu tentang...   \n",
       "\n",
       "                    title                                    url  \n",
       "0  Asam deoksiribonukleat  https://id.wikipedia.org/wiki?curid=1  \n",
       "1             Anwar Sadat  https://id.wikipedia.org/wiki?curid=3  \n",
       "2            Azhar Mansor  https://id.wikipedia.org/wiki?curid=4  \n",
       "3               Arkeologi  https://id.wikipedia.org/wiki?curid=5  \n",
       "4             Antropologi  https://id.wikipedia.org/wiki?curid=6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(f\"{LM_PATH}/Wiki_Indonesia_Corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the title name in the text field\n",
    "def split_title_from_text(text):\n",
    "    words = text.split(\"\\n\\n\")\n",
    "    if len(words) >= 2:\n",
    "        return ''.join(words[1:])\n",
    "    else:\n",
    "        return ''.join(words)\n",
    "    \n",
    "LANG_TEXT['text'] = LANG_TEXT['text'].apply(lambda x: split_title_from_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Asam deoksiribonukleat, lebih dikenal dengan s...</td>\n",
       "      <td>Asam deoksiribonukleat</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Jenderal Besar Mohammed Anwar Al Sadat (; ) ad...</td>\n",
       "      <td>Anwar Sadat</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Datuk Azhar Mansor adalah orang Malaysia perta...</td>\n",
       "      <td>Azhar Mansor</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Arkeologi atau ilmu kepurbakalaan berasal dari...</td>\n",
       "      <td>Arkeologi</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Antropologi adalah ilmu tentang manusia. Antro...</td>\n",
       "      <td>Antropologi</td>\n",
       "      <td>https://id.wikipedia.org/wiki?curid=6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text  \\\n",
       "0  1  Asam deoksiribonukleat, lebih dikenal dengan s...   \n",
       "1  3  Jenderal Besar Mohammed Anwar Al Sadat (; ) ad...   \n",
       "2  4  Datuk Azhar Mansor adalah orang Malaysia perta...   \n",
       "3  5  Arkeologi atau ilmu kepurbakalaan berasal dari...   \n",
       "4  6  Antropologi adalah ilmu tentang manusia. Antro...   \n",
       "\n",
       "                    title                                    url  \n",
       "0  Asam deoksiribonukleat  https://id.wikipedia.org/wiki?curid=1  \n",
       "1             Anwar Sadat  https://id.wikipedia.org/wiki?curid=3  \n",
       "2            Azhar Mansor  https://id.wikipedia.org/wiki?curid=4  \n",
       "3               Arkeologi  https://id.wikipedia.org/wiki?curid=5  \n",
       "4             Antropologi  https://id.wikipedia.org/wiki?curid=6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(f\"{LM_PATH}/Wiki_Indonesia_Corpus2.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the articles by length and keeping the first million (this is actually not necessary for indonesian wiki since it has less than 450k articles in 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = pd.read_csv(f\"{LM_PATH}/Wiki_Indonesia_Corpus2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.assign(length = 0)\n",
    "LANG_TEXT.columns = ['id', 'text', 'title', 'url', 'length']\n",
    "LANG_TEXT = LANG_TEXT.assign(labels = 0).pipe(lambda x: x[['labels', 'text', 'length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jenderal Besar Mohammed Anwar Al Sadat (; ) ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Datuk Azhar Mansor adalah orang Malaysia perta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Arkeologi atau ilmu kepurbakalaan berasal dari...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Antropologi adalah ilmu tentang manusia. Antro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Analisis leksikal (bahasa Inggris: \"lexical an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text  length\n",
       "0       0  Jenderal Besar Mohammed Anwar Al Sadat (; ) ad...       0\n",
       "1       0  Datuk Azhar Mansor adalah orang Malaysia perta...       0\n",
       "2       0  Arkeologi atau ilmu kepurbakalaan berasal dari...       0\n",
       "3       0  Antropologi adalah ilmu tentang manusia. Antro...       0\n",
       "4       0  Analisis leksikal (bahasa Inggris: \"lexical an...       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT['length'] = LANG_TEXT['text'].str.len()\n",
    "LANG_TEXT = LANG_TEXT.sort_values(by=['length'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT.to_csv(f\"{LM_PATH}/Wiki_Indonesia_Corpus2.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LANG_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT[LANG_TEXT['length'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = LANG_TEXT.iloc[0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LANG_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistics of Indonesia Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188440    Technische Hoogeschool te Bandoeng biasa disin...\n",
      "114691    Kemilau Cinta Kamila atau biasa disingkat KCK ...\n",
      "1369      Republik Chili (), kadang-kadang dieja sebagai...\n",
      "4339      Josef Vissarionovich Stalin () adalah pemimpin...\n",
      "5078      Perang Dunia I (PDI) adalah sebuah perang glob...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400256, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(LANG_TEXT['text'][:5])\n",
    "LANG_TEXT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words in all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63094666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LANG_TEXT['text'].apply(lambda x: len(x.split(\" \"))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique tokens across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3575199"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(''.join(LANG_TEXT['text'].values).split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts), lang='xx') # splits the list into sublists for processing by each core\n",
    "    # Lower and upper case is inside the tokenizer\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        #pdb.set_trace()\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TEXT = pd.read_csv(f\"{LM_PATH}/Wiki_Indonesia_Corpus2.csv\", header=None)#, chunksize=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                                  1         2\n",
      "0  0  Technische Hoogeschool te Bandoeng biasa disin...  159917.0\n",
      "1  0  Kemilau Cinta Kamila atau biasa disingkat KCK ...  141607.0\n",
      "2  0  Republik Chili (), kadang-kadang dieja sebagai...  133775.0\n",
      "3  0  Josef Vissarionovich Stalin () adalah pemimpin...  129387.0\n",
      "4  0  Perang Dunia I (PDI) adalah sebuah perang glob...  127190.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(439608, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(LANG_TEXT.head())\n",
    "LANG_TEXT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    LANG_TEXT, test_size=0.1) # split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(trn_texts)) # generate a random ordering\n",
    "val_idx = np.random.permutation(len(val_texts))\n",
    "\n",
    "df_trn = trn_texts.iloc[trn_idx,:] # sort things randomly\n",
    "df_val = val_texts.iloc[val_idx,:] # sort things randomly\n",
    "\n",
    "df_trn.columns = ['labels', 'text', 'length']\n",
    "df_val.columns = ['labels', 'text', 'length']\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False) # saving the data in our new format to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000\n",
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tmp directory to store the upcoming numpy arrays\n",
    "(LM_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "# save the train and validation tokens in the tmp directories\n",
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trn: [['\\n', 'xbos', 'xfld', '1', 'kutambaru', 'merupakan', 'salah', 'satu', 'desa', 'yang', 'ada', 'di', 'kecamatan', 'tiganderket', ',', 'kabupaten', 'karo', ',', 'provinsi', 'sumatera', 'utara', ',', 'indonesia', '.', '\\n ', 'xfld', '1', '123.0'], ['\\n', 'xbos', 'xfld', '1', 'sifaka', 'perrier', '(', '\"', 'propithecus', 'perrieri', '\"', ')', 'adalah', 'seekor', 'lemur', 'endemik', 'madagaskar', '.', 'hewan', 'tersebut', 'dulunya', 'dianggap', 'sebagai', 'subspesies', 'diademed', 'sifakareferensi', '.', '\\n \\n ', 'xfld', '1', '159.0']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Trn:\", tok_trn[:2], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 3671684),\n",
       " ('.', 2873347),\n",
       " ('dan', 1679845),\n",
       " ('yang', 1671563),\n",
       " ('di', 1252995),\n",
       " ('\"', 1229125),\n",
       " ('\\n', 892952),\n",
       " ('1', 846001),\n",
       " ('-', 820121),\n",
       " ('dari', 814579),\n",
       " ('xfld', 791294),\n",
       " ('pada', 769197),\n",
       " ('ini', 753785),\n",
       " ('(', 635694),\n",
       " ('dengan', 629569),\n",
       " ('adalah', 618717),\n",
       " (')', 605809),\n",
       " ('t_up', 525503),\n",
       " ('untuk', 513739),\n",
       " ('dalam', 511064),\n",
       " ('tahun', 413582),\n",
       " ('xbos', 395647),\n",
       " ('oleh', 342616),\n",
       " ('sebagai', 330319),\n",
       " ('juga', 296394)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the most common tokens and numericalizing the text\n",
    "freq = Counter(p for o in tok_trn for p in o) \n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncating our vocab to ignore the rare words\n",
    "max_vocab = 60000\n",
    "min_freq = 5\n",
    "\n",
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq] # getting rid of the rare words\n",
    "itos.insert(0, '_pad_') # \n",
    "itos.insert(0, '_unk_') # itos is the list of all the strings in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a index-key dictionary for our vocabulary\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a index representation for our train and validation dataset\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our indexed representation of our dataset to disk\n",
    "# we also save the index-word mapping to retrieve the complete text representation from these numpy arrays\n",
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the indexed representation of our dataset from disk\n",
    "# we also load the index-word mapping to to help us convert the indexes to word datasets, if need be.\n",
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 395647)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking vocabulary size\n",
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -nH -r -np http://files.fast.ai/models/wt103/\n",
    "# mv models/ {LM_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3\n",
    "\n",
    "PRE_PATH = LM_PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'\n",
    "\n",
    "# itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb')) # mapping the itos from wiki to our own mapping\n",
    "# stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train from scratch so these are unused\n",
    "# wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "# row_m = enc_wgts.mean(0)\n",
    "\n",
    "# wgts['0.encoder.weight'] = T(new_w)\n",
    "# wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "# wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7 # if you're overfitting, increase this. Underfitting? decrease this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.clip = 0.2\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1) # last layer is the embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_indonesia_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_indonesia_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9217cfdc6647dfbfede6f932e231a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 17416/19547 [1:08:16<08:21,  4.25it/s, loss=4.58]"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e6f5af4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = 4e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ffbfee84c14a2bbe90ec3b1a9632bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                         \n",
      "    0      4.22164    4.167298   0.323482  \n",
      "    1      4.230995   4.135004   0.32745                          \n",
      "    2      4.161235   4.042909   0.336713                         \n",
      "    3      4.086843   3.997987   0.341134                         \n",
      "    4      4.101865   3.957439   0.345047                         \n",
      "    5      4.066114   3.929912   0.347438                         \n",
      "    6      4.013648   3.90214    0.349762                         \n",
      "    7      3.985552   3.878478   0.352015                         \n",
      "    8      3.974462   3.857443   0.354098                         \n",
      "    9      3.953277   3.836368   0.35588                          \n",
      "    10     3.967763   3.81269    0.358301                         \n",
      "    11     3.961732   3.795156   0.360286                         \n",
      "    12     3.905945   3.777561   0.361978                         \n",
      "    13     3.941869   3.75649    0.364426                         \n",
      "    14     3.898077   3.73653    0.366791                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.73653]), 0.3667913729591029]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_indonesia_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm_indonesia_final_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'unexpected key \"encoder.weight\" in state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c0e1c625f694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lm_indonesia_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/courses/dl2/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/courses/dl2/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n\u001b[0;32m--> 490\u001b[0;31m                                .format(name))\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mown_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unexpected key \"encoder.weight\" in state_dict'"
     ]
    }
   ],
   "source": [
    "learner.load(\"lm_indonesia_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model\n",
    "m.eval()\n",
    "m[0].bs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"\"\"saya ucapkan terima\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  906, 29687,  4441]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.array([[stoi[p] for p in sen.strip().split(\" \")]])\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   906  29687   4441\n",
       "[torch.cuda.LongTensor of size 1x3 (GPU 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VV(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = learner.model(VV(idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60002)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 60002]),\n",
       " [torch.Size([1, 3, 1150]), torch.Size([1, 3, 1150]), torch.Size([1, 3, 400])],\n",
       " [torch.Size([1, 3, 1150]), torch.Size([1, 3, 1150]), torch.Size([1, 3, 400])])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].shape, [x.shape for x in probs[1]], [x.shape for x in probs[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs[0] is most likely the output vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvind's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp, pos):\n",
    "    idxs = np.array([[stoi[p] for p in inp.strip().split(\" \")]])\n",
    "    p = m(VV(idxs))\n",
    "    top = torch.topk(p[0][-1], 10)\n",
    "    i = top[1].data[pos]\n",
    "    try:\n",
    "        r = itos[i]\n",
    "    except:\n",
    "        r = \"oor\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n, pos):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next_4(inp, pos)\n",
    "        res = res + \" \" + c\n",
    "        inp = inp.strip().split(\" \") + [c]  \n",
    "        inp = ' '.join(inp)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model\n",
    "m.eval()\n",
    "m[0].bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masak sayur - _unk_ , dan _unk_ , dan _unk_ , dan\n",
      "masak sayur , yang telah menjadi \" . _unk_ _unk_ _unk_ _unk_\n",
      "masak sayur dan juga _unk_ . pada _unk_ . pada _unk_ .\n",
      "masak sayur _unk_ ( t_up the world 's \" ( t_up the\n",
      "masak sayur yang pertama kalinya pada waktu itu . \n",
      "  pada waktu\n",
      "masak sayur . di antara . di antara . di antara .\n",
      "masak sayur di luar dari para pemain di luar dari para pemain\n",
      "masak sayur ( dari semua ini telah melakukan aktivitas ekonomi dari semua\n",
      "masak sayur atau sebagai orang dari . dengan tujuan utamanya _unk_ adalah\n",
      "masak sayur \" adalah bagian utara dengan demikian karena telah berhasil dan\n"
     ]
    }
   ],
   "source": [
    "string = \"\"\"masak sayur\"\"\"\n",
    "for i in range(10):\n",
    "    print(get_next_n(string, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kemarin ibu saya masak sayur - _unk_ , dan _unk_ , dan _unk_ , dan\n",
      "kemarin ibu saya masak sayur , yang telah menjadi \" . _unk_ _unk_ _unk_ _unk_\n",
      "kemarin ibu saya masak sayur dan juga _unk_ . pada _unk_ . pada _unk_ .\n",
      "kemarin ibu saya masak sayur _unk_ ( t_up the world 's \" ( t_up the\n",
      "kemarin ibu saya masak sayur yang pertama kalinya pada waktu itu . \n",
      "  pada waktu\n",
      "kemarin ibu saya masak sayur . di antara . di antara . di antara .\n",
      "kemarin ibu saya masak sayur di luar dari para pemain di luar dari para pemain\n",
      "kemarin ibu saya masak sayur ( dari semua ini telah melakukan aktivitas ekonomi dari semua\n",
      "kemarin ibu saya masak sayur atau sebagai orang dari . dengan tujuan utamanya _unk_ adalah\n",
      "kemarin ibu saya masak sayur \" adalah bagian utara dengan demikian karena telah berhasil dan\n"
     ]
    }
   ],
   "source": [
    "sen = \"\"\"masak sayur\"\"\"\n",
    "for i in range(10):\n",
    "    print(get_next_n(sen, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "mywork/Telugu_Language_Model.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
